---
title: "Linear Modeling Dataâ€”so Far"
author: "Ittai Eres"
date: "7/12/2017"
output: html_document
---

```{r Lab Meeting}
library(limma)
library(plyr)
library(tidyr)
library(data.table)
library(reshape2)
library(ggplot2)
library(plotly)
library(dplyr)
library(Hmisc)
library(gplots)
library(stringr)
library(heatmaply)
library(RColorBrewer)
library(edgeR)
library(tidyverse)

###Read in the data, pull out the actual homer-normalized contact frequencies, clean and normalize them.
full.data <- fread("~/Desktop/cis.norm.aug.info", header = TRUE, stringsAsFactors = FALSE, data.table = FALSE)
full.contacts <- full.data[complete.cases(full.data[,302:309]),302:309]
full.norm.data <- as.data.frame(normalizeCyclicLoess(full.contacts, span=1/4, iterations=3, method="pairs"))
full.data <- full.data[complete.cases(full.data[,302:309]),] #Clean up the full data now by removing any NA values in contacts. Note that this removes approximately 50k significant hits. IMPT for proper indexing below:
tss_indices <- which(full.data$hTSS>0&full.data$cTSS>0) #Get the indices for TSS



tss.data <- full.norm.data[tss_indices,]
pairnames <- full.data$HCpair
tsspairs <- pairnames[as.numeric(rownames(tss.data))]
#Metadata on the samples
meta.data <- data.frame("SP"=c("H", "H", "C", "C", "H", "H", "C", "C"), "SX"=c("F", "M", "M", "F", "M", "F", "M", "F"), "Batch"=c(1, 1, 1, 1, 2, 2, 2, 2))
meta.switch <- data.frame("SP"=c("H", "C", "H", "C", "H", "C", "H", "C"), "SX"=c("F", "M", "M", "F", "M", "F", "M", "F"), "Batch"=c(1, 1, 1, 1, 2, 2, 2, 2))


###Making distributions and heatmaps with this data; general initial QC!
hist(full.contacts[,c(1:2,5:6)], main="Final Normalized Contact Frequencies, Humans")
hist(full.contacts[,c(3,4,7,8)], main="Final Normalized Contact Frequencies, Chimps")

corheat <- cor(full.contacts, use="complete.obs", method="pearson") #Corheat for the full data set, and heatmap
colnames(corheat) <- c("A_HF", "B_HM", "C_CM", "D_CF", "E_HM", "F_HF", "G_CM", "H_CF")
rownames(corheat) <- colnames(corheat)
setwd("~/Desktop/")
heatmaply(corheat, main="Pairwise Pearson Correlation @ 25kb", k_row=2, k_col=2, symm=TRUE, file="pearson.heatmap.html", margins=c(50, 50))

cortss <- cor(tss.data, use="complete.obs", method="pearson") #Corheat for the tss data only, and heatmap
colnames(cortss) <- c("A_HF", "B_HM", "C_CM", "D_CF", "E_HM", "F_HF", "G_CM", "H_CF")
rownames(cortss) <- colnames(corheat)
setwd("~/Desktop/")
heatmaply(corheat, main="Pairwise Pearson Correlation @ 25kb", k_row=2, k_col=2, symm=TRUE, file="pearson.heatmap.html", margins=c(50, 50))

###Working on linear modeling with this data
meansdata <- rowMeans(full.contacts) #Check mean against variance
varsdata <- apply(full.contacts, 1, var)
{plot(meansdata, varsdata, main="Mean vs. Variance in Homer-corrected contact frequency")
  abline(lm(meansdata~varsdata), col="red")}

#Look at PCA of normalized data.
#Began to throw an error due to 0-variance rows, remove these from full.contacts first!
varsdata <- unname(varsdata)
zero.indices <- which(varsdata==0)
clean.full.contacts <- full.contacts[-zero.indices,]
pca <- prcomp(t(clean.full.contacts), scale=TRUE, center=TRUE)
ggplot(data=as.data.frame(pca$x), aes(x=PC1, y=PC2, shape=as.factor(meta.data$SP), color=as.factor(meta.data$Batch), size=2)) + geom_point() +labs(title="PCA on normalized Hi-C Contact Frequency") + guides(color=guide_legend(order=1), size=FALSE, shape=guide_legend(order=2)) + xlab(paste("PC1 (", 100*summary(pca)$importance[2,1], "% of variance)")) + ylab((paste("PC2 (", 100*summary(pca)$importance[2,2], "% of variance)")))
barplot(summary(pca)$importance[2,], xlab="PCs", ylab="Proportion of Variance Explained", main="PCA on normalized Hi-C contact frequency")

#Running a linear modeling analysis on the same data, but with scrambled species values balanced across batch
fake_design <- model.matrix(~1+meta.switch$SP+meta.switch$SX+meta.switch$Batch)
ffit <- lmFit(clean.full.contacts, fake_design)
febayes <- eBayes(ffit)
hist(febayes$coefficients[,2])
hist(febayes$p.value[,2])
newqqplot(-log10(febayes$p.value[,2]), c(0.5, 0.75))

#Paramterize a basic design that has species, sex, and batch as covariates. All fixed effects!
basic_design <- model.matrix(~1+meta.data$SP+meta.data$SX+meta.data$Batch)

#Fit the model!
fit <- lmFit(clean.full.contacts, basic_design)
ebayes <- eBayes(fit)
#Pull out betas and pvals for species, look at distributions of each
spbetas <- abs(ebayes$coefficients[,2])
sppvals <- -log10(ebayes$p.value[,2])
hist(ebayes$coefficients[,2], main="Species Betas")
hist(ebayes$coefficients[,3], main="Sex Betas")
hist(ebayes$coefficients[,4], main="Batch Betas")
hist(ebayes$p.value[,2], main="Species p-vals")
hist(ebayes$p.value[,3], main="Sex p-vals")
hist(ebayes$p.value[,4], main="Batch p-vals")
res <- residuals(ebayes, clean.full.contacts)
hist(res, main="Histogram of Residuals", xlab="Residual Values")
#Plot betas against pvals for species, abs(betas) and -log10(pvals)
#{plot(spbetas, sppvals, main="Betas vs. P-vals, Species, Basic LM", xlab="Species Betas", ylab="Species p-vals")}
#{plot(spbetastss, sppvalstss, main="|Betas| vs. -log10(P-vals), Species, Basic LM, TSS only", xlab="|Betas|", ylab="-log10 p-vals")
  #abline(lm(spbetastss~sppvalstss), col="red")}

#Make volcano plot for the info!
volcanoinfo <- topTable(ebayes, number=Inf, coef=2, sort.by = "none")

#volcanoplot(tssebayes, coef=2, style="p-value")
plot(volcanoinfo$logFC, -log10(volcanoinfo$adj.P.Val), col=ifelse(volcanoinfo$adj.P.Val<=0.05, ifelse(volcanoinfo$logFC>=2|volcanoinfo$logFC<=-2, "red", "black"), "black"), xlab="Log2 Fold Change in Contact Frequency", ylab="-log10 BH-corrected p-values", main="Difference in Contact Frequencies b/t Humans and Chimps")

sxvolcanoinfo <- topTable(ebayes, number=Inf, coef=3)
plot(sxvolcanoinfo$logFC, -log10(sxvolcanoinfo$adj.P.Val), col=ifelse(sxvolcanoinfo$adj.P.Val<=0.05, ifelse(sxvolcanoinfo$logFC>=2|sxvolcanoinfo$logFC<=-2, "red", "black"), "black"), xlab="Log2 Fold Change in Contact Frequency", ylab="-log10 BH-corrected p-values", main="Difference in Contact Frequencies b/t Sexes")

btcvolcanoinfo <- topTable(ebayes, number=Inf, coef=4)
plot(btcvolcanoinfo$logFC, -log10(btcvolcanoinfo$adj.P.Val), col=ifelse(btcvolcanoinfo$adj.P.Val<=0.05, ifelse(btcvolcanoinfo$logFC>=2|btcvolcanoinfo$logFC<=-2, "red", "black"), "black"), xlab="Log2 Fold Change in Contact Frequency", ylab="-log10 BH-corrected p-values", main="Difference in Contact Frequencies b/t Sexes")
#plot(tss.res, -log10(volcanoinfo$adj.P.Val))

#Make a qq plot for this data!
#qplot(sample=sppvalstss, data=tss.data)

newqqplot=function(pvals, quant){  
  len = length(pvals)
  res=qqplot(-log10((1:len)/(1+len)),pvals,plot.it=F)
  plot(res$x,res$y, main="QQ plot", xlab="Theoretical", ylab="Actual", col=ifelse(res$y>as.numeric(quantile(res$y, quant[1])), ifelse(res$y>as.numeric(quantile(res$y, quant[2])), "red", "blue"), "black"))
  abline(0, 1)
}

newqqplot(-log10(ebayes$p.value[,2]), c(0.5, 0.75))
newqqplot(-log10(ebayes$p.value[,3]), c(0.5, 0.75))
newqqplot(-log10(ebayes$p.value[,4]), c(0.5, 0.75))

####Enrichment analysis!
#First clean data, then add adjusted p-vals to each row
clean.full.data <- full.data[-zero.indices,]
clean.full.data$signif <- volcanoinfo$adj.P.Val

#Find indices significant at 5% and 10% FDR.
FDR5 <- which(clean.full.data$signif<=0.05)
nonsig5 <- which(clean.full.data$signif>0.05)
FDR10 <- which(clean.full.data$signif<=0.1)
nonsig10 <- which(clean.full.data$signif>0.1)

#Find indices where either bin contains a GWAS hit or an eQTL; and those with a TSS in one or both bins
GWAS <- which((nchar(clean.full.data$bin1GWAS)>1)|(nchar(clean.full.data$bin2GWAS)>1))
tss_both_indices <- which(clean.full.data$hTSS>0&clean.full.data$cTSS>0)
tss_any_indices <- which(clean.full.data$hTSS>0|clean.full.data$cTSS>0)
eQTL <- which(clean.full.data$bin1eQTL>0|clean.full.data$bin2eQTL>0)

enrich.table <- data.frame(insigs=c(length(nonsig5)-sum(tss_both_indices %in% nonsig5), sum(tss_both_indices %in% nonsig5)), sigs=c(length(FDR5)-sum(tss_both_indices %in% FDR5), sum(tss_both_indices %in% FDR5)))
rownames(enrich.table) <- c("No TSS", "TSS")
enrich.mat <- as.matrix(enrich.table)
barplot(as.matrix(enrich.mat[,2]), col=c("red", "blue"), beside=FALSE, main="TSS-containing bins (blue) in Significant hits", names.arg=paste("TSS-containing bins make up ", round(100*(enrich.mat[2,2]/sum(enrich.mat[,2]))), "% of significant hits"))
barplot(as.matrix(enrich.mat[,1]), col=c("red", "blue"), beside=FALSE, main="TSS-containing bins (blue) in Insiginificant hits", names.arg=paste("TSS-containing bins make up ", round(100*(enrich.mat[2,1]/sum(enrich.mat[,1]))), "% of insignificant hits"))
prop.test(enrich.mat)

enrich.table <- data.frame(insigs=c(length(nonsig5)-sum(GWAS %in% nonsig5), sum(GWAS %in% nonsig5)), sigs=c(length(FDR5)-sum(GWAS %in% FDR5), sum(GWAS %in% FDR5)))
enrich.mat <- as.matrix(enrich.table)
barplot(as.matrix(enrich.mat[,2]), col=c("red", "blue"), beside=FALSE, main="GWAS-hit-containing bins (blue) in Significant hits", names.arg=paste("GWAS-hit-containing bins make up ", round(100*(enrich.mat[2,2]/sum(enrich.mat[,2]))), "% of significant hits"))
barplot(as.matrix(enrich.mat[,1]), col=c("red", "blue"), beside=FALSE, main="GWAS-hit-containing bins (blue) in Insiginificant hits", names.arg=paste("GWAS-hit-containing bins make up ", round(100*(enrich.mat[2,1]/sum(enrich.mat[,1]))), "% of insignificant hits"))
prop.test(enrich.mat)

enrich.table <- data.frame(insigs=c(length(nonsig5)-sum(eQTL %in% nonsig5), sum(eQTL %in% nonsig5)), sigs=c(length(FDR5)-sum(eQTL %in% FDR5), sum(eQTL %in% FDR5)))
enrich.mat <- as.matrix(enrich.table)
barplot(as.matrix(enrich.mat[,2]), col=c("red", "blue"), beside=FALSE, main="eQTL-containing bins (blue) in Significant hits", names.arg=paste("eQTL-containing bins make up ", round(100*(enrich.mat[2,2]/sum(enrich.mat[,2]))), "% of significant hits"))
barplot(as.matrix(enrich.mat[,1]), col=c("red", "blue"), beside=FALSE, main="eQTL-containing bins (blue) in Insiginificant hits", names.arg=paste("eQTL-containing bins make up ", 100*(enrich.mat[2,1]/sum(enrich.mat[,1])), "% of insignificant hits"))
prop.test(enrich.mat)

#Find indices where either bin contains a TFBS as assayed by CHIP, top 50% of distribution
TF_chip <- which(((clean.full.data$bin1TFchip)>as.numeric(quantile(clean.full.data$bin1TFchip, 0.5)))|((clean.full.data$bin2TFchip)>as.numeric(quantile(clean.full.data$bin2TFchip, 0.5))))

enrich.table <- data.frame(insigs=c(length(nonsig5)-sum(TFBS %in% nonsig5), sum(TFBS %in% nonsig5)), sigs=c(length(FDR5)-sum(TFBS %in% FDR5), sum(TFBS %in% FDR5)))
enrich.mat <- as.matrix(enrich.table)
barplot(as.matrix(enrich.mat[,2]), col=c("red", "blue"), beside=FALSE, main="Conserved TFBS-containing bins (blue) in Significant hits", names.arg=paste("Conserved TFBS-containing bins make up ", round(100*(enrich.mat[2,2]/sum(enrich.mat[,2]))), "% of significant hits"))
barplot(as.matrix(enrich.mat[,1]), col=c("red", "blue"), beside=FALSE, main="Conserved TFBS-containing bins (blue) in Insiginificant hits", names.arg=paste("Conserved TFBS-containing bins make up ", round(100*(enrich.mat[2,1]/sum(enrich.mat[,1]))), "% of insignificant hits"))
prop.test(enrich.mat)

#Find indices where either bin contains a conserved TFBS , top 50% of distribution
TFBS <- which(((clean.full.data$bin1TFBS_cons_count)>as.numeric(quantile(clean.full.data$bin1TFBS_cons_count, 0.5)))|((clean.full.data$bin2TFBS_cons_count)>as.numeric(quantile(clean.full.data$bin2TFBS_cons_count, 0.5))))

enrich.table <- data.frame(insigs=c(length(nonsig5)-sum(TF_chip %in% nonsig5), sum(TF_chip %in% nonsig5)), sigs=c(length(FDR5)-sum(TF_chip %in% FDR5), sum(TF_chip %in% FDR5)))
enrich.mat <- as.matrix(enrich.table)
barplot(as.matrix(enrich.mat[,2]), col=c("red", "blue"), beside=FALSE, main="TF_chip-containing bins (blue) in Significant hits", names.arg=paste("TF_chip-containing bins make up ", round(100*(enrich.mat[2,2]/sum(enrich.mat[,2]))), "% of significant hits"))
barplot(as.matrix(enrich.mat[,1]), col=c("red", "blue"), beside=FALSE, main="TF_chip-containing bins (blue) in Insiginificant hits", names.arg=paste("TF_chip-containing bins make up ", round(100*(enrich.mat[2,1]/sum(enrich.mat[,1]))), "% of insignificant hits"))
prop.test(enrich.mat)

tss_both_indices <- which(clean.full.data$hTSS>0&clean.full.data$cTSS>0)
tss_any_indices <- which(clean.full.data$hTSS>0|clean.full.data$cTSS>0)
eQTL <- which(clean.full.data$bin1eQTL>0|clean.full.data$bin2eQTL>0)
```




```{r}
library(limma)
library(plyr)
library(tidyr)
library(data.table)
library(reshape2)
library(ggplot2)
library(plotly)
library(dplyr)
library(Hmisc)
library(gplots)
library(stringr)
library(heatmaply)
library(RColorBrewer)
library(edgeR)
library(tidyverse)

#Read in the data, pull out the actual homer-normalized contact frequencies, clean and normalize them.
full.data <- fread("~/Desktop/cis.norm.final.info", header = TRUE, stringsAsFactors = FALSE, data.table = FALSE)
full.contacts <- full.data[complete.cases(full.data[,290:297]),290:297]
full.norm.data <- as.data.frame(normalizeCyclicLoess(full.contacts, span=1/4, iterations=3, method="pairs"))
full.data <- full.data[complete.cases(full.data[,290:297]),] #Clean up the full data now by removing any NA values in contacts. IMPT for proper indexing below:
tss_indices <- which(full.data$hTSS>0&full.data$cTSS>0)
tss.data <- full.norm.data[tss_indices,]
notss.data <- full.norm.data[-tss_indices,]
pairnames <- full.data$HCpair
tsspairs <- pairnames[as.numeric(rownames(tss.data))]
#bjp.data <- data.frame("pairID"=tsspairs, tss.data)
meta.data <- data.frame("Ind"=colnames(tss.data), "SP"=c("H", "H", "C", "C", "H", "H", "C", "C"), "SX"=c("F", "M", "M", "F", "M", "F", "M", "F"), "Batch"=c(1, 1, 1, 1, 2, 2, 2, 2))

#NWork on JUST TSS data!
hist(tss.data, main="Distributions of normalized Hi-C contact frequencies, TSS only") #Look at distribution of contact frequencies.

meanstss <- rowMeans(tss.data) #Check mean against variance
varstss <- apply(tss.data, 1, var)
{plot(meanstss, varstss, main="Mean vs. Variance in Homer-corrected contact frequency aross pairs, TSS only")
  abline(lm(meanstss~varstss), col="red")}

#Look at PCA of normalized TSS data.
pctss <- prcomp(t(tss.data), scale=TRUE, center=TRUE) #Tss chunk
ggplot(data=as.data.frame(pctss$x), aes(x=PC1, y=PC2, shape=as.factor(meta.data$SP), color=as.factor(meta.data$Batch), size=2)) + geom_point() +labs(title="PCA on normalized Hi-C Contact Frequency, TSS only") + guides(color=guide_legend(order=1), size=FALSE, shape=guide_legend(order=2)) + xlab(paste("PC1 (", 100*summary(pctss)$importance[2,1], "% of variance)")) + ylab((paste("PC2 (", 100*summary(pctss)$importance[2,2], "% of variance)")))
barplot(summary(pctss)$importance[2,], xlab="PCs", ylab="Proportion of Variance Explained", main="PCA on normalized Hi-C contact frequency, TSS only")

#Paramterize a basic design that has species as the only covariate.
basic_design <- model.matrix(~1+meta.data$SP)

#Fit the model!
tssfit <- lmFit(tss.data, basic_design)
tssebayes <- eBayes(tssfit)
#Pull out betas and pvals for species, look at distributions of each
spbetastss <- abs(tssebayes$coefficients[,2])
sppvalstss <- -log10(tssebayes$p.value[,2])
hist(tssebayes$coefficients[,2])
hist(tssebayes$p.value[,2])
tss.res <- residuals(tssebayes, tss.data)
hist(tss.res, main="Histogram of Residuals", xlab="Residual Values")
#Plot betas against pvals for species, abs(betas) and -log10(pvals)
#{plot(spbetas, sppvals, main="Betas vs. P-vals, Species, Basic LM", xlab="Species Betas", ylab="Species p-vals")}
#{plot(spbetastss, sppvalstss, main="|Betas| vs. -log10(P-vals), Species, Basic LM, TSS only", xlab="|Betas|", ylab="-log10 p-vals")
  #abline(lm(spbetastss~sppvalstss), col="red")}

#Make volcano plot for the info!
volcanoinfo <- topTable(tssebayes, number=Inf)

volcanoplot(tssebayes, coef=2, style="p-value")
plot(volcanoinfo$logFC, -log10(volcanoinfo$adj.P.Val), col=ifelse(volcanoinfo$adj.P.Val<=0.05, ifelse(volcanoinfo$logFC>=2|volcanoinfo$logFC<=-2, "red", "black"), "black"), xlab="Log2 Fold Change in Contact Frequency", ylab="-log10 BH-corrected p-values", main="Difference in Contact Frequencies b/t Humans and Chimps")

#plot(tss.res, -log10(volcanoinfo$adj.P.Val))

#Make a qq plot for this data!
#qplot(sample=sppvalstss, data=tss.data)

newqqplot=function(pvals, quant){  
  len = length(pvals)
  res=qqplot(-log10((1:len)/(1+len)),pvals,plot.it=F)
  plot(res$x,res$y, main="QQ plot", xlab="Theoretical", ylab="Actual", col=ifelse(res$y>as.numeric(quantile(res$y, quant[1])), ifelse(res$y>as.numeric(quantile(res$y, quant[2])), "red", "blue"), "black"))
  abline(0, 1)
}

col.vec <- ifelse(sppvalstss>0.8604806, "red", "black")
col.vec[which(sppvalstss>1.824802)] <- "blue"

newqqplot(sppvalstss, c(0.75, 0.9))


###################Adding in random effect
 #Now again, but with a model that includes a random effect per individual, as done using duplicateCorrelation.
base_design <- model.matrix(~1 + meta.data$SP)
corfit <- duplicateCorrelation(tss.data, base_design)
corfit.correlation <- corfit$consensus.correlation
fit <- lmFit(tss.data, basic_design, correlation=corfit.correlation)
efit <- eBayes(fit)

##Do everything I did above, but only for the non-TSS set...
hist(notss.data, main="Distributions of normalized Hi-C contact frequencies, notss only") #Look at distribution of contact frequencies.

meansnotss <- rowMeans(notss.data) #Check mean against variance
varsnotss <- apply(notss.data, 1, var)
{plot(meansnotss, varsnotss, main="Mean vs. Variance in Homer-corrected contact frequency aross pairs, notss only")
  abline(lm(meansnotss~varsnotss), col="red")}

#Look at PCA of normalized notss data.
pcnotss <- prcomp(t(notss.data), scale=TRUE, center=TRUE) #notss chunk
ggplot(data=as.data.frame(pcnotss$x), aes(x=PC1, y=PC2, shape=as.factor(meta.data$SP), color=as.factor(meta.data$Batch), size=2)) + geom_point() +labs(title="PCA on normalized Hi-C Contact Frequency, notss only") + guides(color=guide_legend(order=1), size=FALSE, shape=guide_legend(order=2)) + xlab(paste("PC1 (", 100*summary(pcnotss)$importance[2,1], "% of variance)")) + ylab((paste("PC2 (", 100*summary(pcnotss)$importance[2,2], "% of variance)")))
barplot(summary(pcnotss)$importance[2,], xlab="PCs", ylab="Proportion of Variance Explained", main="PCA on normalized Hi-C contact frequency, notss only")

#Paramterize a basic design that has species as the only covariate.
basic_design <- model.matrix(~1+meta.data$SP)

#Fit the model!
notssfit <- lmFit(notss.data, basic_design)
notssebayes <- eBayes(notssfit)
#Pull out betas and pvals for species, look at distributions of each
spbetasnotss <- abs(notssebayes$coefficients[,2])
sppvalsnotss <- -log10(notssebayes$p.value[,2])
hist(notssebayes$coefficients[,2])
hist(notssebayes$p.value[,2])
notss.res <- residuals(notssebayes, notss.data)
hist(notss.res, main="Histogram of Residuals", xlab="Residual Values")
#Plot betas against pvals for species, abs(betas) and -log10(pvals)
#{plot(spbetas, sppvals, main="Betas vs. P-vals, Species, Basic LM", xlab="Species Betas", ylab="Species p-vals")}
#{plot(spbetasnotss, sppvalsnotss, main="|Betas| vs. -log10(P-vals), Species, Basic LM, notss only", xlab="|Betas|", ylab="-log10 p-vals")
  #abline(lm(spbetasnotss~sppvalsnotss), col="red")}

#Make volcano plot for the info!
volcanoinfo <- topTable(notssebayes, number=Inf)

volcanoplot(notssebayes, coef=2, style="p-value")
plot(volcanoinfo$logFC, -log10(volcanoinfo$adj.P.Val), col=ifelse(volcanoinfo$adj.P.Val<=0.05, ifelse(volcanoinfo$logFC>=2|volcanoinfo$logFC<=-2, "red", "black"), "black"), xlab="Log2 Fold Change in Contact Frequency", ylab="-log10 BH-corrected p-values", main="Difference in Contact Frequencies b/t Humans and Chimps")

#plot(notss.res, -log10(volcanoinfo$adj.P.Val))

#Make a qq plot for this data!
#qplot(sample=sppvalsnotss, data=notss.data)

newqqplot=function(pvals, quant){  
  len = length(pvals)
  res=qqplot(-log10((1:len)/(1+len)),pvals,plot.it=F)
  plot(res$x,res$y, main="QQ plot", xlab="Theoretical", ylab="Actual", col=ifelse(res$y>as.numeric(quantile(res$y, quant[1])), ifelse(res$y>as.numeric(quantile(res$y, quant[2])), "red", "blue"), "black"))
  abline(0, 1)
}

col.vec <- ifelse(sppvalsnotss>0.8604806, "red", "black")
col.vec[which(sppvalsnotss>1.824802)] <- "blue"

newqqplot(sppvalsnotss, c(0.75, 0.9))


# 
# #Pull out betas and pvals for species, look at distributions of each
# spbetastss <- abs(efit$coefficients[,2])
# sppvalstss <- -log10(efit$p.value[,2])
# hist(efit$coefficients[,2])
# hist(efit$p.value[,2])
# tss.res <- residuals(efit, tss.data)
# hist(tss.res, main="Histogram of Residuals", xlab="Residual Values")
# #Plot betas against pvals for species, abs(betas) and -log10(pvals)
# #{plot(spbetas, sppvals, main="Betas vs. P-vals, Species, Basic LM", xlab="Species Betas", ylab="Species p-vals")}
# #{plot(spbetastss, sppvalstss, main="|Betas| vs. -log10(P-vals), Species, Basic LM, TSS only", xlab="|Betas|", ylab="-log10 p-vals")
#   #abline(lm(spbetastss~sppvalstss), col="red")}
# 
# #Make volcano plot for the info!
# volcanoinfo <- topTable(efit, number=Inf, coef=2, sort.by="none", adjust="BH")
# 
# volcanoplot(efit, coef=2, style="p-value")
# plot(volcanoinfo$logFC, -log10(volcanoinfo$adj.P.Val), col=ifelse(volcanoinfo$adj.P.Val<=0.05, ifelse(volcanoinfo$logFC>=2|volcanoinfo$logFC<=-2, "red", "black"), "black"), xlab="Log2 Fold Change in Contact Frequency", ylab="-log10 BH-corrected p-values", main="Difference in Contact Frequencies b/t Humans and Chimps")
# 
# plot(tss.res, -log10(volcanoinfo$adj.P.Val))
# 
# #Make a qq plot for this data!
# #qplot(sample=sppvalstss, data=tss.data)
# 
# newqqplot=function(pvals, quant){  
#   len = length(pvals)
#   res=qqplot(-log10((1:len)/(1+len)),pvals,plot.it=F)
#   plot(res$x,res$y, main="QQ plot", xlab="Theoretical", ylab="Actual", col=ifelse(res$y>as.numeric(quantile(res$y, quant[1])), ifelse(res$y>as.numeric(quantile(res$y, quant[2])), "red", "blue"), "black"))
#   abline(0, 1)
# }
# 
# col.vec <- ifelse(sppvalstss>0.8604806, "red", "black")
# col.vec[which(sppvalstss>1.824802)] <- "blue"
# 
# newqqplot(sppvalstss, c(0.75, 0.9))


#Other covariates to consider: are these individuals related at all?
#Check distribution of entire contact frequencies from homer, expectation of normal distribution around 0
#Generally expect betas to correlate with their pvals, but depends on standard error
#Are some of the stronger beta/pval hits clustered somewhere? Are they correlated with each other/localized in the same region? Are they more likely to be enriched for A or B compartment, some other kind of enrichment??? Or enriched for within-TAD or between-TAD contacts? Using a classifier for TAD membership and assigning this as another element of the linear model (is that even possible?)?
#Add other sequencing lanes, get A and B compartments in 5kb intervals to help w/ GWAS fxnal integration


# #####################################
# #First, just look at distributions of normalized Hi-C contact frequencies.
# hist(full.norm.data, main="Distributions of normalized Hi-C contact frequencies")
# hist(tss.data, main="Distributions of normalized Hi-C contact frequencies, TSS only")
# hist(notss.data, main="Distributions of normalized Hi-C contact frequencies, no TSS")
# 
# #Do PCA on the normalized data, look at PC1 vs. PC2 and see what it separates out!
# pc <- prcomp(t(full.norm.data), scale=TRUE, center=TRUE)
# species <- c("H", "H", "C", "C", "H", "H", "C", "C")
# sex <- c("F", "M", "M", "F", "M", "F", "M", "F")
# batch <- c("early", "early", "early", "early", "late", "late", "late", "late")
# ggplot(data=as.data.frame(pc$x), aes(x=PC1, y=PC2, shape=as.factor(species), color=as.factor(sex), size=2)) + geom_point() +labs(title="PCA on normalized Hi-C Contact Frequency") + guides(color=guide_legend(order=1), size=FALSE, shape=guide_legend(order=2)) + xlab(paste("PC1 (", 100*summary(pc)$importance[2,1], "% of variance)")) + ylab((paste("PC2 (", 100*summary(pc)$importance[2,2], "% of variance)")))
# barplot(summary(pc)$importance[2,], xlab="PCs", ylab="Proportion of Variance Explained", main="PCA on normalized Hi-C contact frequency")
# 
# #PC1 appears to be strongly correlated with species, but PC2 is still indeterminate...examination of the other PCs do not seem to line up with any other known covariates (batch, sex, etc.)
# 
# #Now do PCA again, but on normalized data in two chunks: tss chunk and no tss chunk...
# pcnotss <- prcomp(t(notss.data), scale=TRUE, center=TRUE) #Tss chunk
# ggplot(data=as.data.frame(pcnotss$x), aes(x=PC1, y=PC2, shape=as.factor(species), color=as.factor(batch), size=2)) + geom_point() +labs(title="PCA on normalized Hi-C Contact Frequency, no TSS") + guides(color=guide_legend(order=1), size=FALSE, shape=guide_legend(order=2)) + xlab(paste("PC1 (", 100*summary(pcnotss)$importance[2,1], "% of variance)")) + ylab((paste("PC2 (", 100*summary(pcnotss)$importance[2,2], "% of variance)")))
# barplot(summary(pcnotss)$importance[2,], xlab="PCs", ylab="Proportion of Variance Explained", main="PCA on normalized Hi-C contact frequency, no TSS")
# 
# #Plot mean vs variance by contact; can see relatively flat relationship b/t the two
# means <- rowMeans(full.norm.data)
# vars <- apply(full.norm.data, 1, var)
# {plot(means, vars, main="Mean vs. Variance in Homer-corrected contact frequency aross pairs")
#   abline(lm(means~vars), col="red")}
# 
# #Same thing but on the set of TSS-containing pairs and on the set of no-TSS containing pairs.
# meanstss <- rowMeans(tss.data)
# varstss <- apply(tss.data, 1, var)
# {plot(meanstss, varstss, main="Mean vs. Variance in Homer-corrected contact frequency aross pairs, TSS only")
#   abline(lm(meanstss~varstss), col="red")}
# 
# meansnotss <- rowMeans(notss.data)
# varsnotss <- apply(notss.data, 1, var)
# {plot(meansnotss, varsnotss, main="Mean vs. Variance in Homer-corrected contact frequency aross pairs, no TSS")
#   abline(lm(meansnotss~varsnotss), col="red")}
# 
# #Try running a linear model! Very basic one with species as the only predictor.
# species <- c(0,0,1,1,0,0,1,1)
# basic_design <- model.matrix(~1+species)
# 
# fullfit <- lmFit(full.norm.data, basic_design)
# fullebayes <- eBayes(fullfit)
# 
# #Pull out betas and pvals for species, look at distributions of each. Do the same for residuals.
# spbetas <- abs(fullebayes$coefficients[,2])
# sppvals <- -log10(fullebayes$p.value[,2])
# hist(fullebayes$coefficients[,2])
# hist(fullebayes$p.value[,2])
# full.res <- residuals(fullebayes, full.norm.data)
# hist(full.res)
# 
# #Plot betas against pvals for species, abs(betas) and -log10(pvals)
# #{plot(spbetas, sppvals, main="Betas vs. P-vals, Species, Basic LM", xlab="Species Betas", ylab="Species p-vals")}
# {plot(spbetas, sppvals, main="|Betas| vs. -log10(P-vals), Species, Basic LM", xlab="|Betas|", ylab="-log10 p-vals")
#   abline(lm(spbetas~sppvals), col="red")}
# 
# #Make qqplot to check p-values
# newqqplot(sppvals, always.plot=-1)
# 
# #Take a look at PCA of residuals!
# pcres <- prcomp(t(full.res), scale=TRUE, center=TRUE)
# ggplot(data=as.data.frame(pcres$x), aes(x=PC1, y=PC2, shape=as.factor(sex), color=as.factor(batch), size=2)) + geom_point() +labs(title="PCA on residuals from full linear model") + guides(color=guide_legend(order=1), size=FALSE, shape=guide_legend(order=2)) + xlab(paste("PC1 (", 100*summary(pcres)$importance[2,1], "% of variance)")) + ylab((paste("PC2 (", 100*summary(pcres)$importance[2,2], "% of variance)")))
# barplot(summary(pcres)$importance[2,], xlab="PCs", ylab="Proportion of Variance Explained", main="PCA on residuals from full linear model")
# 
# #All this stuff again, but only on TSS-containing set, and then only on set not containing TSS.
# tssfit <- lmFit(tss.data, basic_design)
# tssebayes <- eBayes(tssfit)
# #Pull out betas and pvals for species, look at distributions of each
# spbetastss <- abs(tssebayes$coefficients[,2])
# sppvalstss <- -log10(tssebayes$p.value[,2])
# hist(tssebayes$coefficients[,2])
# hist(tssebayes$p.value[,2])
# tss.res <- residuals(tssebayes, tss.data)
# hist(tss.res)
# #Plot betas against pvals for species, abs(betas) and -log10(pvals)
# #{plot(spbetas, sppvals, main="Betas vs. P-vals, Species, Basic LM", xlab="Species Betas", ylab="Species p-vals")}
# {plot(spbetastss, sppvalstss, main="|Betas| vs. -log10(P-vals), Species, Basic LM, TSS only", xlab="|Betas|", ylab="-log10 p-vals")
#   abline(lm(spbetastss~sppvalstss), col="red")}
# #Make qqplot to check p-values
# newqqplot(sppvalstss, always.plot=-1)
# #Take a look at PCA of residuals!
# pcrestss <- prcomp(t(tss.res), scale=TRUE, center=TRUE)
# ggplot(data=as.data.frame(pcrestss$x), aes(x=PC1, y=PC2, shape=as.factor(sex), color=as.factor(batch), size=2)) + geom_point() +labs(title="PCA on residuals from full linear model, TSS only") + guides(color=guide_legend(order=1), size=FALSE, shape=guide_legend(order=2)) + xlab(paste("PC1 (", 100*summary(pcrestss)$importance[2,1], "% of variance)")) + ylab((paste("PC2 (", 100*summary(pcrestss)$importance[2,2], "% of variance)")))
# barplot(summary(pcrestss)$importance[2,], xlab="PCs", ylab="Proportion of Variance Explained", main="PCA on residuals from full linear model, TSS only")
# 
# notssfit <- lmFit(notss.data, basic_design)
# notssebayes <- eBayes(notssfit)
# #Pull out betas and pvals for species, look at distributions of each
# spbetasnotss <- abs(notssebayes$coefficients[,2])
# sppvalsnotss <- -log10(notssebayes$p.value[,2])
# hist(notssebayes$coefficients[,2])
# hist(notssebayes$p.value[,2])
# notss.res <- residuals(notssebayes, notss.data)
# hist(notss.res)
# #Plot betas against pvals for species, abs(betas) and -log10(pvals)
# #{plot(spbetas, sppvals, main="Betas vs. P-vals, Species, Basic LM", xlab="Species Betas", ylab="Species p-vals")}
# {plot(spbetasnotss, sppvalsnotss, main="|Betas| vs. -log10(P-vals), Species, Basic LM, no TSS", xlab="|Betas|", ylab="-log10 p-vals")
#   abline(lm(spbetasnotss~sppvalsnotss), col="red")}
# #Make qqplot to check p-values
# newqqplot(sppvalsnotss, always.plot=-1)
# #Take a look at PCA of residuals!
# pcresnotss <- prcomp(t(notss.res), scale=TRUE, center=TRUE)
# ggplot(data=as.data.frame(pcresnotss$x), aes(x=PC1, y=PC2, shape=as.factor(sex), color=as.factor(batch), size=2)) + geom_point() +labs(title="PCA on residuals from full linear model, no TSS") + guides(color=guide_legend(order=1), size=FALSE, shape=guide_legend(order=2)) + xlab(paste("PC1 (", 100*summary(pcresnotss)$importance[2,1], "% of variance)")) + ylab((paste("PC2 (", 100*summary(pcresnotss)$importance[2,2], "% of variance)")))
# barplot(summary(pcresnotss)$importance[2,], xlab="PCs", ylab="Proportion of Variance Explained", main="PCA on residuals from full linear model, no TSS")
# 
# 
# 
# ######Try doing everything again, with a slightly more complicated model that also includes batch and sex as covariates.
# batch <- c(0, 0, 0, 0, 1, 1, 1, 1) #0 for batch 1, 1 for batch 2
# sex <- c(1, 0, 0, 1, 0, 1, 0, 1) #1 for female, 0 for male
# complex.design <- model.matrix(~1+species+batch+sex)
# 
# fullfit <- lmFit(full.norm.data, complex.design)
# fullebayes <- eBayes(fullfit)
# 
# #Pull out betas and pvals for species, look at distributions of each. Do the same for residuals.
# spbetas <- abs(fullebayes$coefficients[,2])
# sppvals <- -log10(fullebayes$p.value[,2])
# hist(fullebayes$coefficients[,2])
# hist(fullebayes$p.value[,2])
# full.res <- residuals(fullebayes, full.norm.data)
# hist(full.res)
# 
# #Plot betas against pvals for species, abs(betas) and -log10(pvals)
# #{plot(spbetas, sppvals, main="Betas vs. P-vals, Species, Basic LM", xlab="Species Betas", ylab="Species p-vals")}
# {plot(spbetas, sppvals, main="|Betas| vs. -log10(P-vals), Species, Basic LM", xlab="|Betas|", ylab="-log10 p-vals")
#   abline(lm(spbetas~sppvals), col="red")}
# 
# #Make qqplot to check p-values
# newqqplot(sppvals, always.plot=-1)
# 
# #Take a look at PCA of residuals!
# pcres <- prcomp(t(full.res), scale=TRUE, center=TRUE)
# ggplot(data=as.data.frame(pcres$x), aes(x=PC1, y=PC2, shape=as.factor(sex), color=as.factor(batch), size=2)) + geom_point() +labs(title="PCA on residuals from full linear model") + guides(color=guide_legend(order=1), size=FALSE, shape=guide_legend(order=2)) + xlab(paste("PC1 (", 100*summary(pcres)$importance[2,1], "% of variance)")) + ylab((paste("PC2 (", 100*summary(pcres)$importance[2,2], "% of variance)")))
# barplot(summary(pcres)$importance[2,], xlab="PCs", ylab="Proportion of Variance Explained", main="PCA on residuals from full linear model")
# 
# #All this stuff again, but only on TSS-containing set, and then only on set not containing TSS.
# tssfit <- lmFit(tss.data, complex.design)
# tssebayes <- eBayes(tssfit)
# #Pull out betas and pvals for species, look at distributions of each
# spbetastss <- abs(tssebayes$coefficients[,2])
# sppvalstss <- -log10(tssebayes$p.value[,2])
# hist(tssebayes$coefficients[,2])
# hist(tssebayes$p.value[,2])
# tss.res <- residuals(tssebayes, tss.data)
# hist(tss.res)
# #Plot betas against pvals for species, abs(betas) and -log10(pvals)
# #{plot(spbetas, sppvals, main="Betas vs. P-vals, Species, Basic LM", xlab="Species Betas", ylab="Species p-vals")}
# {plot(spbetastss, sppvalstss, main="|Betas| vs. -log10(P-vals), Species, Basic LM, TSS only", xlab="|Betas|", ylab="-log10 p-vals")
#   abline(lm(spbetastss~sppvalstss), col="red")}
# #Make qqplot to check p-values
# newqqplot(sppvalstss, always.plot=-1)
# #Take a look at PCA of residuals!
# pcrestss <- prcomp(t(tss.res), scale=TRUE, center=TRUE)
# ggplot(data=as.data.frame(pcrestss$x), aes(x=PC1, y=PC2, shape=as.factor(sex), color=as.factor(batch), size=2)) + geom_point() +labs(title="PCA on residuals from full linear model, TSS only") + guides(color=guide_legend(order=1), size=FALSE, shape=guide_legend(order=2)) + xlab(paste("PC1 (", 100*summary(pcrestss)$importance[2,1], "% of variance)")) + ylab((paste("PC2 (", 100*summary(pcrestss)$importance[2,2], "% of variance)")))
# barplot(summary(pcrestss)$importance[2,], xlab="PCs", ylab="Proportion of Variance Explained", main="PCA on residuals from full linear model, TSS only")
# 
# notssfit <- lmFit(notss.data, complex.design)
# notssebayes <- eBayes(notssfit)
# #Pull out betas and pvals for species, look at distributions of each
# spbetasnotss <- abs(notssebayes$coefficients[,2])
# sppvalsnotss <- -log10(notssebayes$p.value[,2])
# hist(notssebayes$coefficients[,2])
# hist(notssebayes$p.value[,2])
# notss.res <- residuals(notssebayes, notss.data)
# hist(notss.res)
# #Plot betas against pvals for species, abs(betas) and -log10(pvals)
# #{plot(spbetas, sppvals, main="Betas vs. P-vals, Species, Basic LM", xlab="Species Betas", ylab="Species p-vals")}
# {plot(spbetasnotss, sppvalsnotss, main="|Betas| vs. -log10(P-vals), Species, Basic LM, no TSS", xlab="|Betas|", ylab="-log10 p-vals")
#   abline(lm(spbetasnotss~sppvalsnotss), col="red")}
# #Make qqplot to check p-values
# newqqplot(sppvalsnotss, always.plot=-1)
# #Take a look at PCA of residuals!
# pcresnotss <- prcomp(t(notss.res), scale=TRUE, center=TRUE)
# ggplot(data=as.data.frame(pcresnotss$x), aes(x=PC1, y=PC2, shape=as.factor(sex), color=as.factor(batch), size=2)) + geom_point() +labs(title="PCA on residuals from full linear model, no TSS") + guides(color=guide_legend(order=1), size=FALSE, shape=guide_legend(order=2)) + xlab(paste("PC1 (", 100*summary(pcresnotss)$importance[2,1], "% of variance)")) + ylab((paste("PC2 (", 100*summary(pcresnotss)$importance[2,2], "% of variance)")))
# barplot(summary(pcresnotss)$importance[2,], xlab="PCs", ylab="Proportion of Variance Explained", main="PCA on residuals from full linear model, no TSS")
```